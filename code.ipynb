{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6abf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd02652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd ## extension panda pour gérer des données géographiques\n",
    "import folium ## permet de créer des cartes interactives\n",
    "import requests ## pour faire des requêtes HTTP pour récupérer des données en ligne\n",
    "from matplotlib import pyplot as plt ## partie de la bibliothèque Matplotlib utilisée pour faire des graphiques.\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.preprocessing import StandardScaler ## onctions de SciPy pour faire du clustering hiérarchique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point ## Shapely est une bibliothèque Python utilisée pour manipuler des objets géométriques (points, lignes, polygones) dans un contexte géospatial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac17cf",
   "metadata": {},
   "source": [
    "Ouverture du fichier sur les données sociodémographiques des IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenus = pd.read_csv(\"revenus.csv\", sep=\";\")\n",
    "revenus.head()\n",
    "## nous chargeons un fichier CSV nommé \"revenus.csv\" en utilisant la bibliothèque pandas et nous affichons les premières lignes du DataFrame résultant avec la méthode head().\n",
    "## Ce tableau statistique de l'INSEE contient une colonne d'indentification géographique (IRIS) et de nombreuses colonnes de variables sur les revenus (médiane, déciles, quartiles, indices d’inégalité, parts de prestations, impôts, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae304ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenus.columns = (\n",
    "    revenus.columns\n",
    "    .str.replace(\"^DISP_\", \"\", regex=True)   # enlève le préfixe DISP_\n",
    "    .str.replace(\"18$\", \"\", regex=True)      # enlève le suffixe 18\n",
    "    .str.lower()                             # met en minuscules\n",
    ")\n",
    "print(revenus.columns)\n",
    "## Ici on nettoie les noms des colonnes du DataFrame en supprimant certains préfixes et suffixes spécifiques, et en convertissant tous les noms de colonnes en minuscules pour une meilleure lisibilité et cohérence. Ainsi on retir le préfixe \"DISP_\" et le suffixe \"18\" des noms de colonnes, puis on convertit tous les noms en minuscules. Enfin, on affiche les nouveaux noms de colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b56a32",
   "metadata": {},
   "source": [
    " Ici on nettoie les noms des colonnes du DataFrame en supprimant certains préfixes et suffixes spécifiques, et en convertissant tous les noms de colonnes en minuscules pour une meilleure lisibilité et cohérence. Ainsi on retir le préfixe \"DISP_\" et le suffixe \"18\" des noms de colonnes, puis on convertit tous les noms en minuscules. Enfin, on affiche les nouveaux noms de colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70b558",
   "metadata": {},
   "source": [
    "CAH\n",
    "Faire un indice synthétique pour pouvoir représenter facilement les caractéristiques structurelles des quartiers sur une carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenus.shape\n",
    "## nombre de zones géographiques (lignes) et de variables (colonnes) dans le DataFrame revenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a38568",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenus.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9db8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on retire la colonne IRIS qui correspond aux identifiants, \n",
    "# la colonne DISP_TP6018 (23% de NA) et la note de précaution\n",
    "rev_cah = revenus.drop(columns=[\"iris\", \"tp60\", \"note\", \"d2\", \"d3\", \"d4\", \"d6\", \"d7\", \"d8\"])\n",
    "print(rev_cah.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161285bd",
   "metadata": {},
   "source": [
    "La commande revenus.isna().sum() sert à vérifier les valeurs manquantes dans ton DataFrame.revenus.isna() crée un tableau de la même taille que revenus où chaque cellule vaut :\n",
    "- True si la valeur est manquante (NaN)\n",
    "- False sinon\n",
    "#.sum() fait la somme par colonne, donc on obtient le nombre de valeurs manquantes pour chaque colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on vérifie qu'on n'a que des valeurs numériques\n",
    "rev_cah.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579a03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation des valeurs manquantes\n",
    "for col in rev_cah.columns:\n",
    "    rev_cah[col] = rev_cah[col].fillna(rev_cah[col].median())\n",
    "\n",
    "# vérification\n",
    "rev_cah.isna().sum()\n",
    "\n",
    "## Ce code remplace toutes les valeurs manquantes par la médiane de leur colonne et vérifie ensuite qu’il n’en reste plus. Cela prépare les données pour l’analyse ou le clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation\n",
    "scaler = StandardScaler()\n",
    "rev_scaled = scaler.fit_transform(rev_cah)\n",
    "\n",
    "## La normalisation transforme les données pour que chaque colonne ait moyenne 0 et écart type 1, ce qui évite qu’une variable domine les autres et permet des analyses plus fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAH\n",
    "Z = linkage(rev_scaled, method='ward')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(Z, truncate_mode=\"level\", p=5)\n",
    "plt.title(\"Dendrogramme CAH\")\n",
    "plt.show()\n",
    "\n",
    "## Ce code réalise une Clustering Ascendant Hiérarchique (CAH) sur les données de revenus normalisées pour regrouper les IRIS aux caractéristiques similaires. La méthode de Ward est utilisée pour minimiser la variance à l’intérieur des clusters. Le dendrogramme affiché montre visuellement comment les IRIS sont regroupés et permet d’identifier le nombre de clusters pertinent pour analyser les profils socio-économiques des zones.*\n",
    "## Expliquer comment on lit le dendrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a4ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = Z[:, 2]  # distances des fusions\n",
    "last_rev = last[::-1]  # inversé pour l’ordre croissant\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 16), last_rev[:15], marker='o')\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"Distance de fusion\")\n",
    "plt.title(\"Méthode du coude (1 à 15 clusters)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## On utilise la distance des fusions pour tracer une courbe et identifier le “coude”, c’est-à-dire le nombre de clusters où fusionner davantage devient peu utile. C’est une méthode visuelle et pratique pour déterminer le nombre optimal de clusters.\n",
    "## L'axe x correspond au nombre de clusters et l'axe y à la distance de fusion (indique à quel point les clusters groupés sont différents). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Découpage en clusters\n",
    "clusters = fcluster(Z, 5, criterion='maxclust') ## on choisit 5 clusters\n",
    "revenus[\"cluster\"] = clusters\n",
    "\n",
    "# Résumé\n",
    "print(revenus[\"cluster\"].value_counts()) ## affiche le nombre d'IRIS dans chaque cluster\n",
    "\n",
    "vars_to_summarize = [\"tp60\", \"med\", \"rd\", \"gi\", \"pact\", \"ppat\", \"ppsoc\"] ## on utilise seulement certaines variables pour le résumé\n",
    "\n",
    "summary = revenus.groupby(\"cluster\")[vars_to_summarize].mean() ## pour chaque variable, on calcule la moyenne dans chaque cluster\n",
    "total = revenus[vars_to_summarize].mean()\n",
    "summary_with_total = pd.concat([summary, total.to_frame().T], axis=0)\n",
    "summary_with_total.index = list(summary.index) + [\"Total\"]\n",
    "\n",
    "print(summary_with_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e74b527",
   "metadata": {},
   "source": [
    "Dans un premier temps, ce code attribue chaque IRIS à un cluster (le clustering se fait par rapport à toutes les variables).\n",
    "Ensuite, ce code de résume les caractéristiques socio-économiques des clusters obtenus par la classification. Il compte d’abord combien d’IRIS appartiennent à chaque groupe, puis calcule la moyenne de plusieurs variables représentatives (revenu médian, inégalités, part d’actifs, etc.) pour chaque cluster. Il ajoute enfin la moyenne globale du dataset pour permettre une comparaison. Le tableau final permet donc de comprendre le profil typique de chaque cluster par rapport à l’ensemble du territoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = revenus.groupby(\"cluster\").mean(numeric_only=True) ## calculer la moyenne des colonnes numériques pour chaque cluster\n",
    "total = revenus.mean(numeric_only=True) ## calculer la moyenne générale de toutes les colonnes numériques\n",
    "summary_with_total = pd.concat([summary, total.to_frame().T], axis=0) ## crée un DataFrame avec les moyennes par cluster + une ligne summplémentaire avec la moyenne générale\n",
    "summary_with_total.index = list(summary.index) + [\"Total\"]\n",
    "\n",
    "print(summary_with_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77052430",
   "metadata": {},
   "source": [
    "Après le clustering, chaque IRIS appartient à un groupe (cluster) ayant des caractéristiques similaires.\n",
    "\n",
    "Le tableau summary te montre les moyennes par cluster pour les variables importantes (revenu médian, déciles, parts de prestations, etc.).\n",
    "\n",
    "Ça permet de comparer les clusters entre eux : par exemple, quel cluster a les revenus les plus élevés, ou les inégalités les plus fortes.\n",
    "\n",
    "La ligne Total représente la moyenne globale pour toutes les données, sans distinction de cluster. Elle sert de référence pour savoir si un cluster est au-dessus ou en dessous de la moyenne générale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8af83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_order = revenus.groupby(\"cluster\")[\"med\"].median().sort_values()\n",
    "print(cluster_order)\n",
    "labels = [\"tres_pauvre\", \"pauvre\", \"moyen\", \"riche\", \"tres_riche\"]\n",
    "mapping = {cluster: labels[i] for i, cluster in enumerate(cluster_order.index)}\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49506c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenus[\"cluster_label\"] = revenus[\"cluster\"].map(mapping)\n",
    "print(revenus[\"cluster_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf114c",
   "metadata": {},
   "source": [
    "Fusionner avec les contours des IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb943de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_iris = gpd.read_file(\"contours-iris-pe.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e188cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_iris = gdf_iris.merge(\n",
    "    revenus,\n",
    "    left_on=\"code_iris\",\n",
    "    right_on=\"iris\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(gdf_iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a019c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_iris.isna().sum())\n",
    "gdf_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea065c",
   "metadata": {},
   "source": [
    "Données démographiques sur les IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2963824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv(\"population.csv\", sep=\";\")\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.columns = (\n",
    "    population.columns\n",
    "    .str.replace(\"^P21_\", \"\", regex=True)   # enlève le préfixe DISP_\n",
    "    .str.replace(\"^C21_\", \"\", regex=True)      # enlève le suffixe 18\n",
    "    .str.lower()                             # met en minuscules\n",
    ")\n",
    "print(population.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"meta_population.csv\", sep=\";\")\n",
    "\n",
    "# garder seulement les lignes correspondant à la variable IRIS\n",
    "meta_iris = meta[meta[\"COD_VAR\"] == \"IRIS\"]\n",
    "\n",
    "# ne garder que le code et le nom\n",
    "meta_iris = meta_iris[[\"COD_MOD\", \"LIB_MOD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de56dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_iris[\"COD_MOD\"] = (\n",
    "    meta_iris[\"COD_MOD\"].astype(str)\n",
    "                        .apply(lambda x: x[1:] if x.startswith(\"0\") else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "population[\"iris\"] = population[\"iris\"].astype(str)\n",
    "meta_iris[\"COD_MOD\"] = meta_iris[\"COD_MOD\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = population.merge(\n",
    "    meta_iris,\n",
    "    left_on=\"iris\",\n",
    "    right_on=\"COD_MOD\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec699434",
   "metadata": {},
   "outputs": [],
   "source": [
    "population[[\"iris\", \"LIB_MOD\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247234ba",
   "metadata": {},
   "source": [
    "Fusion des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48173ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_iris = gdf_iris.merge(\n",
    "    population,\n",
    "    left_on=\"code_iris\",\n",
    "    right_on=\"COD_MOD\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(gdf_iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292133c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_iris[[\"pop\", \"pop_fr\"]].isna().sum())\n",
    "gdf_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_typ_iris = {\n",
    "    \"H\": \"habitat\",\n",
    "    \"A\": \"activité\",\n",
    "    \"D\": \"divers\",\n",
    "    \"Z\": \"autre\"\n",
    "}\n",
    "\n",
    "gdf_iris[\"type_iris_label\"] = gdf_iris[\"type_iris\"].map(mapping_typ_iris)\n",
    "gdf_iris[\"type_iris_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5c831",
   "metadata": {},
   "source": [
    "Ouverture du fichier parcoursup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e560669",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcoursup = \"parcoursup.csv\"\n",
    "\n",
    "df = pd.read_csv(parcoursup, sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser toutes les colonnes\n",
    "df.columns = [\n",
    "    col.lower()  # tout en minuscules\n",
    "       .replace(' ', '_')       # espaces → _\n",
    "       .replace(\"'\", \"_\")       # apostrophes → _\n",
    "       .replace('(', '')        # supprimer (\n",
    "       .replace(')', '')        # supprimer )\n",
    "       .replace(',', '')        # supprimer ,\n",
    "       .replace('.', '')        # supprimer .\n",
    "       .replace('…', '')\n",
    "       .replace('é','e')        # accents\n",
    "       .replace('è','e')\n",
    "       .replace('à','a')\n",
    "       .replace('ê','e')\n",
    "       .replace('ç','c')\n",
    "       .replace('%','percent')\n",
    "       for col in df.columns\n",
    "]\n",
    "\n",
    "# Vérifier le résultat\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb6d08",
   "metadata": {},
   "source": [
    "Relier les IRIS à parcoursup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20695220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"coordonnees_gps_de_la_formation\": \"coord_gps\"})\n",
    "\n",
    "df[['latitude', 'longitude']] = df['coord_gps'].str.split(',', expand=True)\n",
    "df['latitude'] = df['latitude'].astype(float)\n",
    "df['longitude'] = df['longitude'].astype(float)\n",
    "\n",
    "# Vérifier\n",
    "df[['latitude','longitude']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\"   # CRS WGS84 pour des coordonnées GPS\n",
    ")\n",
    "\n",
    "df_points[['geometry']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b0182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des IRIS en EPSG:4326\n",
    "gdf_iris = gdf_iris.to_crs(epsg=4326)\n",
    "\n",
    "# Vérifier le CRS\n",
    "print(gdf_iris.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points = df_points.set_crs(4326)\n",
    "gdf_iris = gdf_iris.set_crs(4326)\n",
    "\n",
    "df_total = gpd.sjoin(\n",
    "    df_points, \n",
    "    gdf_iris[['code_iris', 'nom_iris', 'geometry', 'nom_commune', 'type_iris', \"med\", \"rd\", \"ppsoc\", \"cluster_label\", \"pop\", \"pop1117\", \"pop1824\", \"pop15p_cs3\", \"pop15p_cs5\", \"pop15p_cs6\", \"pop_imm\"]], \n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127bb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_total.isna()[[\"pop\", \"pop_imm\", \"code_iris\"]].sum())\n",
    "print(df_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec71e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"code_iris\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fe742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"selectivite\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Nombre total de formations par IRIS\n",
    "total_form = (\n",
    "    df_total.groupby(\"code_iris\")\n",
    "      .size()\n",
    "      .reset_index(name=\"nb_formations\")\n",
    ")\n",
    "\n",
    "# 2. Nombre de formations sélectives par IRIS\n",
    "selectives = (\n",
    "    df_total[df_total[\"selectivite\"] == \"formation sélective\"]\n",
    "    .groupby(\"code_iris\")\n",
    "    .size()\n",
    "    .reset_index(name=\"nb_form_sel\")\n",
    ")\n",
    "\n",
    "# 3. Fusion des deux résultats\n",
    "result = total_form.merge(selectives, on=\"code_iris\", how=\"left\")\n",
    "\n",
    "# Les IRIS sans formation sélective → 0\n",
    "result[\"nb_form_sel\"] = result[\"nb_form_sel\"].fillna(0).astype(int)\n",
    "\n",
    "result.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_total.columns:\n",
    "    if \"taux\" in col.lower():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"taux_d’acces\"].quantile([0.25, 0.333, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0312b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_total[\"taux_d’acces\"] < 50).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43fa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[\"percent_d’admis_neo_bacheliers_boursiers\"].quantile([0.25, 0.333, 0.5, 0.667, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80331de",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_total[\"percent_d’admis_neo_bacheliers_boursiers\"] < 30).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ae968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer les colonnes pour les formations très sélectives et avec un haut taux de boursiers\n",
    "df_total[\"tres_select\"] = df_total[\"taux_d’acces\"] < 50\n",
    "df_total[\"bcp_boursiers\"] = df_total[\"percent_d’admis_neo_bacheliers_boursiers\"] > 30\n",
    "\n",
    "# compter par IRIS\n",
    "result2 = df_total.groupby(\"code_iris\")[[\"tres_select\", \"bcp_boursiers\"]].sum().reset_index()\n",
    "\n",
    "# fusionner aux autres colonnes créées \n",
    "result3 = result.merge(result2, on=\"code_iris\", how=\"left\")\n",
    "\n",
    "# afficher\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afc86d",
   "metadata": {},
   "source": [
    "Ajouter ces colonnes à la base sur les iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_iris = gdf_iris.merge(result3, on=\"code_iris\", how=\"left\")\n",
    "gdf_iris[[\"nb_formations\", \"nb_form_sel\", \"tres_select\", \"bcp_boursiers\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e84302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer les NaN par 0 pour les colonnes issues des données parcoursup\n",
    "gdf_iris[\"nb_formations\"] = gdf_iris[\"nb_formations\"].fillna(0)\n",
    "\n",
    "# Vérification\n",
    "gdf_iris[\"nb_formations\"].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_iris[\"nb_formations_cat\"] = \"0\"\n",
    "\n",
    "# sélectionner les valeurs > 0\n",
    "mask = gdf_iris[\"nb_formations\"] > 0\n",
    "\n",
    "# créer les quantiles sur le reste\n",
    "gdf_iris.loc[mask, \"nb_formations_cat\"] = pd.qcut(gdf_iris.loc[mask, \"nb_formations\"], \n",
    "                                            q=2, \n",
    "                                            labels=[\"Q1\",\"Q2\"])\n",
    "\n",
    "gdf_iris.groupby(\"nb_formations_cat\")[\"pop\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20db5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrer la carte sur Besançon\n",
    "besancon_lon, besancon_lat = 6.025, 47.237\n",
    "m = folium.Map(location=[besancon_lat, besancon_lon], zoom_start=13)\n",
    "\n",
    "# Ajouter les polygones IRIS\n",
    "folium.GeoJson(\n",
    "    gdf_iris,\n",
    "    name=\"IRIS\",\n",
    "    style_function=lambda x: {\"fillColor\": \"blue\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0.2}\n",
    ").add_to(m)\n",
    "\n",
    "# Filtrer les points valides\n",
    "df_points_valid = df_points.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "#Boucle sur les points valides\n",
    "for idx, row in df_points_valid.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=3,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.7\n",
    "    ).add_to(m)\n",
    "\n",
    "# Ajouter contrôle des couches\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Afficher la carte\n",
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ajouter un code département à partir du code IRIS\n",
    "gdf_iris[\"code_iris\"] = gdf_iris[\"code_iris\"].astype(str)\n",
    "gdf_iris[\"code_dept\"] = gdf_iris[\"code_iris\"].str[:2]\n",
    "\n",
    "# 2) Garder uniquement l'Île-de-France\n",
    "idf_deps = [\"75\", \"77\", \"78\", \"91\", \"92\", \"93\", \"94\", \"95\"]\n",
    "gdf_idf = gdf_iris[gdf_iris[\"code_dept\"].isin(idf_deps)].copy()\n",
    "\n",
    "print(\"Nombre d'IRIS en IDF :\", gdf_idf.shape[0])\n",
    "\n",
    "# 3) Palette de couleurs pour les types de quartiers (clusters)\n",
    "cluster_colors = {\n",
    "    \"tres_pauvre\": \"#b30000\",  # rouge foncé\n",
    "    \"pauvre\":      \"#fc8d59\",  # orange\n",
    "    \"moyen\":       \"#fee08b\",  # jaune\n",
    "    \"riche\":       \"#91bfdb\",  # bleu clair\n",
    "    \"tres_riche\":  \"#4575b4\",  # bleu foncé\n",
    "}\n",
    "\n",
    "def style_cluster(feature):\n",
    "    label = feature[\"properties\"].get(\"cluster_label\")\n",
    "    color = cluster_colors.get(label, \"#cccccc\")  # gris si NaN\n",
    "    return {\n",
    "        \"fillColor\": color,\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.3,\n",
    "        \"fillOpacity\": 0.6,\n",
    "    }\n",
    "\n",
    "# 4) Filtrer les formations qui sont dans un IRIS IDF\n",
    "idf_iris_codes = set(gdf_idf[\"code_iris\"].astype(str).unique())\n",
    "\n",
    "df_points_idf = df_total[\n",
    "    df_total[\"code_iris\"].astype(str).isin(idf_iris_codes)\n",
    "].dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "print(\"Nombre de formations en IDF :\", df_points_idf.shape[0])\n",
    "\n",
    "# 5) Créer une carte centrée sur Paris\n",
    "m = folium.Map(\n",
    "    location=[48.8566, 2.3522],\n",
    "    zoom_start=10,\n",
    "    max_zoom=10,\n",
    "    min_zoom=10,\n",
    "    dragging=False,\n",
    "    scrollWheelZoom=False,\n",
    "    doubleClickZoom=False,\n",
    "    zoomControl=False\n",
    ")\n",
    "\n",
    "\n",
    "# 6) Ajouter les polygones IRIS colorés selon le type de quartier\n",
    "folium.GeoJson(\n",
    "    gdf_idf,\n",
    "    name=\"Quartiers (IRIS)\",\n",
    "    style_function=style_cluster,\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=[\"nom_iris\", \"nom_commune\", \"cluster_label\"],\n",
    "        aliases=[\"IRIS\", \"Commune\", \"Type de quartier\"],\n",
    "        localize=True\n",
    "    ),\n",
    ").add_to(m)\n",
    "\n",
    "# 7) Ajouter les formations en points rouges\n",
    "for _, row in df_points_idf.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=1,\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "    ).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "#m\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bebca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "# Construire la variable dépendante binaire Y = has_selective\n",
    "# nb_form_sel = nombre de formations \"formation sélective\" dans l'IRIS (calculé plus haut)\n",
    "# Si nb_form_sel est manquant (IRIS sans formation), on met 0.\n",
    "gdf_iris[\"nb_form_sel\"] = gdf_iris[\"nb_form_sel\"].fillna(0)\n",
    "\n",
    "# Variable binaire : 1 si au moins une formation sélective, 0 sinon\n",
    "gdf_iris[\"has_selective\"] = (gdf_iris[\"nb_form_sel\"] > 0).astype(int)\n",
    "\n",
    "print(\"Répartition de has_selective (0/1) :\")\n",
    "print(gdf_iris[\"has_selective\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construire un dataframe d'estimation propre (sans géométrie)\n",
    "# Un logit ne doit pas recevoir la colonne geometry (qui n'est pas numérique)\n",
    "# On garde uniquement les colonnes utiles au modèle.\n",
    "# Ici, le coeur du modèle : C(cluster_label)\n",
    "# Et (optionnel) quelques contrôles démographiques/sociaux.\n",
    "vars_cont = [\"ppsoc\", \"med\", \"pop1824\",\"pop15p_cs5\"] \n",
    "# Colonnes catégorielles : cluster_label (obligatoire), type_iris_label (optionnel si dispo)\n",
    "cat_vars = [\"cluster_label\"]\n",
    "if \"type_iris_label\" in gdf_iris.columns:\n",
    "    cat_vars.append(\"type_iris_label\")\n",
    "\n",
    "# Colonnes finales utilisées\n",
    "cols_needed = [\"has_selective\"] + cat_vars + [v for v in vars_cont if v in gdf_iris.columns]\n",
    "\n",
    "df_model = gdf_iris[cols_needed].copy()\n",
    "\n",
    "# Nettoyage : on enlève les lignes avec NA sur les variables du modèle\n",
    "df_model = df_model.dropna()\n",
    "\n",
    "print(\"\\nColonnes utilisées dans df_model :\")\n",
    "print(df_model.columns.tolist())\n",
    "print(\"Taille de l'échantillon :\", df_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e105f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécifier le modèle logit (formule)\n",
    "# C(cluster_label) indique à statsmodels que cluster_label est catégorielle (dummies auto)\n",
    "# La catégorie de référence est choisie automatiquement (souvent ordre alphabétique).\n",
    "# Si tu veux imposer une référence (ex. \"tres_pauvre\"), on peut le faire ensuite.\n",
    "terms = [\"C(cluster_label, Treatment(reference='moyen'))\"]\n",
    "\n",
    "# Ajout de type_iris_label si présent\n",
    "if \"type_iris_label\" in df_model.columns:\n",
    "    terms.append(\"C(type_iris_label)\")\n",
    "\n",
    "# Ajout des contrôles continus disponibles\n",
    "for v in vars_cont:\n",
    "    if v in df_model.columns:\n",
    "        terms.append(v)\n",
    "\n",
    "formula = \"has_selective ~ \" + \" + \".join(terms)\n",
    "print(\"\\nFormule estimée :\")\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef88bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimer le logit par maximum de vraisemblance\n",
    "\n",
    "logit_model = smf.logit(formula=formula, data=df_model)\n",
    "logit_results = logit_model.fit()\n",
    "\n",
    "print(\"\\nRésumé du logit :\")\n",
    "print(logit_results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14e131",
   "metadata": {},
   "source": [
    "Interprétation des résultats du modèle logit :\n",
    "\n",
    "Le tableau ci-dessus présente les résultats d’un modèle logit estimant la probabilité pour un quartier (IRIS) d’accueillir au moins une formation sélective. La variable dépendante est binaire et vaut 1 si l’IRIS comporte au moins une formation sélective, 0 sinon. Le modèle est estimé par maximum de vraisemblance sur un échantillon de 11 424 IRIS et a convergé correctement.\n",
    "\n",
    "Qualité globale du modèle:\n",
    "\n",
    "Le test du rapport de vraisemblance (LLR p-value < 10⁻¹²⁰) permet de rejeter très nettement l’hypothèse nulle selon laquelle l’ensemble des coefficients seraient nuls. Le modèle explique donc significativement la présence de formations sélectives. Le pseudo-R² s’élève à environ 5,8 %, ce qui est un niveau courant pour un modèle logit appliqué à des données spatiales et suggère que, bien que le modèle capte une part non négligeable des déterminants, une fraction importante de la localisation des formations reste expliquée par des facteurs non observés.\n",
    "\n",
    "Lecture des coefficients associés aux types de quartiers:\n",
    "\n",
    "Les coefficients estimés pour les types de quartiers sont exprimés en *log-odds* et doivent être interprétés relativement à une catégorie de référence. Dans ce modèle, les quartiers de type *moyen* constituent la catégorie de référence. Ainsi, chaque coefficient mesure l’écart de probabilité d’accueillir une formation sélective entre un type de quartier donné et un quartier moyen, toutes choses égales par ailleurs.\n",
    "\n",
    "Un coefficient négatif indique que le type de quartier considéré a une probabilité plus faible que les quartiers moyens d’accueillir une formation sélective, tandis qu’un coefficient positif indique une probabilité plus élevée. Pour faciliter l’interprétation, ces coefficients peuvent être exponentiés afin d’obtenir des *odds ratios*, qui indiquent le facteur multiplicatif des chances relatives par rapport à la catégorie de référence.\n",
    "\n",
    "Effet du type socio-économique du quartier:\n",
    "\n",
    "Les quartiers *pauvres* présentent une probabilité significativement plus faible que les quartiers moyens d’accueillir une formation sélective. Cet écart est encore plus prononcé pour les quartiers *très pauvres*, dont la probabilité est fortement réduite par rapport à celle des quartiers moyens.\n",
    "À l’autre extrémité de la distribution, les quartiers *très riches* se distinguent nettement des quartiers moyens par une probabilité significativement plus élevée d’accueillir une formation sélective. L’exponentiation du coefficient associé montre que les chances relatives d’implantation y sont plus de deux fois supérieures à celles observées dans les quartiers moyens. En revanche, les quartiers *riches* ne diffèrent pas significativement des quartiers moyens au seuil de 5 %, suggérant que l’avantage spatial se concentre principalement dans les quartiers les plus favorisés, et non de manière monotone avec le niveau de richesse.\n",
    "\n",
    "Ces résultats révèlent une forte non-linéarité des inégalités socio-spatiales : les quartiers très riches concentrent une part disproportionnée de l’offre sélective, tandis que les quartiers pauvres et très pauvres sont nettement désavantagés.\n",
    "\n",
    "Effet du type fonctionnel de l’IRIS:\n",
    "\n",
    "Le modèle contrôle également pour le type fonctionnel des IRIS. À caractéristiques socio-économiques comparables, les IRIS à dominante résidentielle (*habitat*) présentent une probabilité plus faible d’accueillir une formation sélective que les IRIS d’activité, ce qui reflète une logique d’implantation liée à la présence d’infrastructures universitaires et de pôles d’enseignement.\n",
    "\n",
    "Variables de contrôle démographiques et sociales:\n",
    "\n",
    "Parmi les variables continues, la population âgée de 18 à 24 ans a un effet positif et fortement significatif : les quartiers comptant davantage de jeunes adultes ont une probabilité plus élevée d’accueillir des formations sélectives, ce qui est cohérent avec une logique de proximité à la population étudiante.\n",
    "\n",
    "Le revenu médian apparaît avec un coefficient négatif conditionnellement aux clusters de quartiers, ce qui suggère que l’effet du niveau de revenu est déjà largement capturé par la typologie socio-économique globale. De même, la part des cadres et la part des prestations sociales dans le revenu ne présentent pas d’effet significatif une fois ces typologies prises en compte, indiquant une redondance informationnelle avec les clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974044d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpréter en odds ratios (plus lisible que les log-odds)\n",
    "# Les coefficients du logit sont en log-odds.\n",
    "# Exp(coef) donne un odds ratio : multiplicateur des odds quand la variable augmente.\n",
    "odds_ratios = np.exp(logit_results.params).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nOdds ratios (exp(coefficients)) :\")\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b150d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ça on comprend pas comment ça marche\n",
    "#Calculer les probabilités prédites (p_hat) pour chaque IRIS du df_model\n",
    "df_model[\"p_hat\"] = logit_results.predict(df_model)\n",
    "\n",
    "print(\"\\nRésumé des probabilités prédites :\")\n",
    "print(df_model[\"p_hat\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réinjecter les probabilités prédites dans gdf_iris pour cartographie\n",
    "# On réassocie les p_hat à gdf_iris via l'index (car df_model vient de gdf_iris)\n",
    "gdf_iris.loc[df_model.index, \"p_hat\"] = df_model[\"p_hat\"]\n",
    "\n",
    "print(\"\\nColonne 'p_hat' ajoutée dans gdf_iris (extrait) :\")\n",
    "print(gdf_iris[[\"has_selective\", \"nb_form_sel\", \"cluster_label\", \"p_hat\"]].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
